import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, Optional
from numpy.polynomial import Polynomial
import os
import json

# -----------------------------------------------------------
# Load exported pump patterns and geometry
# -----------------------------------------------------------
export_dir = "./pump_patterns_cifar10"  # Updated for CIFAR-10

# Check if patterns exist, if not will be generated by pump_pattern_trial.py
if os.path.exists(os.path.join(export_dir, "pump_patterns.npz")):
    data = np.load(os.path.join(export_dir, "pump_patterns.npz"))
    patterns = data["patterns"]
    betas = data["betas"]
    PIs = data["PIs"]

    with open(os.path.join(export_dir, "geo_info.json")) as f:
        geo_info = json.load(f)

    print(f"Loaded pump data from {export_dir}")
    print(f"Available connections: {patterns.shape[0]} x {patterns.shape[1]} (M x N)")
    print(f"Expected: 10 outputs x 128 inputs for CIFAR-10")
else:
    print(f"Warning: Pump patterns not found in {export_dir}")
    print("Run pump_pattern_trial.py first to generate patterns for CIFAR-10")
    # Create dummy patterns for demonstration
    patterns = np.random.rand(10, 128, 200, 300) * 0.5
    betas = np.random.uniform(0.3, 0.9, (10, 128))
    PIs = np.random.uniform(0.5, 1.5, (10, 128))
    geo_info = []
    for i in range(10):
        for j in range(128):
            geo_info.append({
                "nx": 300, "ny": 200, "dx": 2e-6, "dy": 2e-6,
                "r_in": (30, 100), "r_out": (270, 100)
            })

# -----------------------------------------------------------
# Pick one connection to simulate, e.g., (0,0)
# -----------------------------------------------------------
conn_i, conn_j = 0, 0  # change these indices to select others

P = patterns[conn_i, conn_j]
geo_dict = geo_info[conn_i * patterns.shape[1] + conn_j]

# Reconstruct geometry object
class Geo:
    pass

geo = Geo()
geo.nx = geo_dict["nx"]
geo.ny = geo_dict["ny"]
geo.dx = geo_dict["dx"]
geo.dy = geo_dict["dy"]
geo.r_in = tuple(geo_dict["r_in"])
geo.r_out = tuple(geo_dict["r_out"])

print(f"Selected connection ({conn_i},{conn_j})")
print(f"β = {betas[conn_i, conn_j]:.3f}, PI = {PIs[conn_i, conn_j]:.3f}")


# -----------------------
# Utility / helper funcs
# -----------------------
def sample_line_pixels(pump_pattern: np.ndarray, geo, r_in, r_out, n_samples: int):
    """
    Return pump values sampled along the straight line from r_in to r_out.
    r_in, r_out given as pixel coordinates (x_idx, y_idx).
    pump_pattern shape: (ny, nx)
    n_samples: number of z-steps along the path
    """
    ny, nx = pump_pattern.shape
    x0, y0 = r_in
    x1, y1 = r_out
    xs = np.linspace(x0, x1, n_samples)
    ys = np.linspace(y0, y1, n_samples)
    # nearest neighbor sample
    xi = np.clip(np.round(xs).astype(int), 0, nx-1)
    yi = np.clip(np.round(ys).astype(int), 0, ny-1)
    vals = pump_pattern[yi, xi]  # note pattern[y,x]
    return vals, (xi, yi)

# -----------------------
# Propagation simulator
# -----------------------
def propagate_through_pumped_material(I_in_vals: np.ndarray,
                                      pump_pattern: np.ndarray,
                                      geo,
                                      r_in: Tuple[int,int], r_out: Tuple[int,int],
                                      dz_steps: int = 200,
                                      dz_m: Optional[float] = None,
                                      alpha_lin: float = 50.0,   # baseline absorption per meter
                                      g0: float = 200.0,         # linear pump gain scale (per meter)
                                      k_nl: float = 500.0,       # nonlinear pump-assisted coefficient (per W/m)
                                      Isat: float = 1e-3
                                     ) -> np.ndarray:
    """
    Simulate I->O relation for inputs I_in_vals given a pump_pattern and geometry.
    Returns O_out array of same shape as I_in_vals.
    NOTE: units are arbitrary; tune alpha_lin, g0, k_nl to get desirable shapes.
    """
    # Compute physical length L from geo (pixel coords -> meters)
    # geo expected to have attributes: dx, dy, r_in, r_out, nx, ny
    x0, y0 = r_in
    x1, y1 = r_out
    dx = geo.dx
    dy = geo.dy
    Lx = (x1 - x0) * dx
    Ly = (y1 - y0) * dy
    L = np.hypot(Lx, Ly)
    if dz_m is None:
        dz = L / dz_steps
    else:
        dz = dz_m
        dz_steps = max(2, int(np.ceil(L / dz)))
    # sample pump values along path
    pump_vals, (xi, yi) = sample_line_pixels(pump_pattern, geo, r_in, r_out, dz_steps)
    # convert pump (assumed normalized 0..1) to local linear gain and local nonlinear coeff
    # g_lin(z) = g0 * pump, g_nl(z) = k_nl * pump
    g_lin_profile = g0 * pump_vals
    g_nl_profile  = k_nl * pump_vals

    O_out = np.zeros_like(I_in_vals, dtype=float)
    for idx, I0 in enumerate(I_in_vals):
        I = float(I0)
        for s in range(dz_steps):
            g_lin = g_lin_profile[s]
            g_nl  = g_nl_profile[s]
            # saturable-like modulation of linear term optionally:
            # alpha_eff = alpha_lin / (1 + I/Isat)
            # Using simpler linear alpha here:
            alpha_eff = alpha_lin / (1.0 + I/Isat)
            dI = (g_lin - alpha_eff) * I * dz + g_nl * (I**2) * dz
            I += dI
            # keep physically non-negative
            if I < 0:
                I = 0.0
        O_out[idx] = I
    return O_out

# -----------------------
# Fitting utilities
# -----------------------
def fit_polynomial(I_in: np.ndarray, O_out: np.ndarray, deg: int = 5) -> np.ndarray:
    # Fit polynomial on the original scale (not log), but ensure non-negative fit if desired
    # using numpy.polyfit; returns coefficients highest->lowest
    # To avoid runaway, clip negative O_out to small positive before fit
    mask = O_out >= 0
    if O_out.min() < 0:
        O_fit = np.clip(O_out, 0.0, None)
    else:
        O_fit = O_out
    coeffs = np.polyfit(I_in, O_fit, deg)
    return coeffs  # highest->lowest

def dominant_log_slope(I_in: np.ndarray, O_out: np.ndarray, low_frac=0.1, high_frac=0.9):
    # estimate slope d ln O / d ln I by linear fit on log-log in a middle region
    # exclude zeros
    mask = (I_in > 0) & (O_out > 0)
    if mask.sum() < 3:
        return np.nan
    Ipos = I_in[mask]
    Opos = O_out[mask]
    # pick middle chunk
    low = np.quantile(Ipos, low_frac)
    high = np.quantile(Ipos, high_frac)
    mid_mask = (Ipos >= low) & (Ipos <= high)
    if mid_mask.sum() < 2:
        return np.nan
    logI = np.log(Ipos[mid_mask])
    logO = np.log(Opos[mid_mask])
    # linear regression
    slope, intercept = np.polyfit(logI, logO, 1)
    return slope

# -----------------------
# Demo runner
# -----------------------
def demo_run(pump_pattern: Optional[np.ndarray] = None):
    # If pump_pattern not provided, create a demo segmented mask
    ny, nx = 200, 300
    class SimpleGeo: pass
    geo = SimpleGeo()
    geo.nx = nx
    geo.ny = ny
    geo.dx = 2e-6
    geo.dy = 2e-6
    # choose input/output pixel positions (x_idx, y_idx)
    r_in  = (30, 40)   # left-side microring
    r_out = (270, 160) # right-side grating

    if pump_pattern is None:
        # build a simple segmented striped mask to mimic earlier patterns
        pump_pattern = np.zeros((ny, nx), dtype=float)
        # stripe pattern across the path region
        y = np.arange(ny)
        x = np.arange(nx)
        X, Y = np.meshgrid(x, y)
        # make pumped stripes along x direction near the middle y region
        stripe_y = (Y > 80) & (Y < 120)
        period = 20
        stripe_x = ((X % period) < 6)  # duty approx 0.3
        pump_pattern[stripe_y & stripe_x] = 1.0
        # soften with gaussian envelope centered on line
        # compute distance from line
        x0, y0 = r_in
        x1, y1 = r_out
        xs = (X - x0)
        ys = (Y - y0)
        # parametric distance to line
        dx = (x1 - x0) * geo.dx
        dy = (y1 - y0) * geo.dy
        L = np.hypot(dx, dy)
        ux = dx / L
        uy = dy / L
        # approximate physical distances (in pixels -> meters)
        # find distance of each pixel center to line
        # project to line coordinate s
        s = ( (X - x0)*ux + (Y - y0)*uy )
        # gaussian envelope
        sigma_pixels = 25
        env = np.exp(-((Y - (y0 + (y1-y0)/2))**2) / (2 * sigma_pixels**2))
        pump_pattern = pump_pattern * env
        # normalize
        pump_pattern = pump_pattern / pump_pattern.max()

    # Input range
    I_in = np.linspace(1e-6, 1.0, 80)  # normalized input powers

    # Simulate
    O_out = propagate_through_pumped_material(I_in, pump_pattern, geo, r_in, r_out,
                                             dz_steps=400,
                                             alpha_lin=200.0,
                                             g0=500.0,
                                             k_nl=2000.0,
                                             Isat=1e-3)

    # Fit polynomial
    deg = 5
    coeffs = fit_polynomial(I_in, O_out, deg=deg)
    p = np.poly1d(coeffs)

    # Dominant log slope
    slope = dominant_log_slope(I_in, O_out, low_frac=0.2, high_frac=0.9)

    # Plot results
    plt.figure(figsize=(6,4))
    plt.imshow(pump_pattern, cmap='inferno', origin='lower', aspect='auto')
    plt.scatter([r_in[0]], [r_in[1]], c='cyan', marker='o', s=80, edgecolors='white', label='Input')
    plt.scatter([r_out[0]], [r_out[1]], c='lime', marker='X', s=80, label='Output')
    plt.title('Pump Pattern (normalized)')
    plt.legend()
    plt.axis('off')
    plt.show()

    plt.figure(figsize=(6,4))
    plt.plot(I_in, O_out, 'o', markersize=4, label='Simulated O')
    I_plot = np.linspace(I_in.min(), I_in.max(), 300)
    plt.plot(I_plot, p(I_plot), '-', label=f'Poly fit deg={deg}')
    plt.xlabel('Input power (arb)')
    plt.ylabel('Output power (arb)')
    plt.title(f'I→O transfer (log-slope ≈ {slope:.2f})')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Print coefficients (highest->lowest)
    print("Polynomial fit coeffs (highest->lowest):")
    print(coeffs)
    print(f"Estimated dominant log-log slope: {slope:.3f}")

    return I_in, O_out, coeffs, slope, pump_pattern

# If run as script, do demo
if __name__ == "__main__":
    # Range of input powers
    I_in = np.linspace(1e-6, 1.0, 80)

    # Create storage arrays
    all_coeffs = []
    all_slopes = []
    combined_pattern = np.zeros_like(patterns[0, 0])

    plt.figure(figsize=(7, 5))
    for i in range(patterns.shape[0]):
        for j in range(patterns.shape[1]):
            # Select pattern and geometry
            P = patterns[i, j]
            geo_dict = geo_info[i * patterns.shape[1] + j]

            # Reconstruct geometry object
            geo.nx = geo_dict["nx"]
            geo.ny = geo_dict["ny"]
            geo.dx = geo_dict["dx"]
            geo.dy = geo_dict["dy"]
            geo.r_in = tuple(geo_dict["r_in"])
            geo.r_out = tuple(geo_dict["r_out"])

            # Run nonlinear propagation
            O_out = propagate_through_pumped_material(
                I_in,
                P,
                geo,
                geo.r_in,
                geo.r_out,
                dz_steps=400,
                alpha_lin=200.0,
                g0=500.0,
                k_nl=2000.0,
                Isat=1e-3
            )

            # Fit polynomial and slope
            coeffs = fit_polynomial(I_in, O_out, deg=5)
            slope = dominant_log_slope(I_in, O_out)
            all_coeffs.append(coeffs)
            all_slopes.append(slope)

            # Overlay I/O curves
            I_fit = np.linspace(I_in.min(), I_in.max(), 300)
            plt.plot(I_fit, np.poly1d(coeffs)(I_fit),
                     label=f"({i},{j}) β={betas[i,j]:.2f}, slope={slope:.2f}")

            # Add to combined pump image
            combined_pattern += P

    plt.xlabel("Input Power (arb.)")
    plt.ylabel("Output Power (arb.)")
    plt.title("Overlapped I/O Power Curves for All Connections")
    plt.legend(fontsize=7)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Normalize and plot combined pump pattern
    combined_pattern /= combined_pattern.max()
    plt.figure(figsize=(8, 5))
    plt.imshow(combined_pattern, cmap='inferno', origin='lower', aspect='auto')
    plt.title("Combined Pump Pattern (All Connections Overlapped)")
    plt.axis('off')
    plt.show()

    # Print summary
    print("\nSummary of all connections:")
    for idx, coeff in enumerate(all_coeffs):
        i, j = divmod(idx, patterns.shape[1])
        print(f"({i},{j}) β={betas[i,j]:.2f}, slope={all_slopes[idx]:.2f}")
        print("  Coeffs:", np.round(coeff, 4))

import pickle
import torchvision
import torchvision.transforms as transforms

export_dir = "./pump_patterns_cifar10"

# Load pump patterns and metadata
if os.path.exists(os.path.join(export_dir, "pump_patterns.npz")):
    data = np.load(os.path.join(export_dir, "pump_patterns.npz"))
    patterns = data["patterns"]
    betas = data["betas"]
    PIs = data["PIs"]
    with open(os.path.join(export_dir, "geo_info.json")) as f:
        geo_info = json.load(f)
    print("Loaded pump patterns for CIFAR-10")
else:
    print("Warning: Using placeholder patterns")
    patterns = np.random.rand(10, 128, 200, 300) * 0.5
    betas = np.random.uniform(0.3, 0.9, (10, 128))
    PIs = np.random.uniform(0.5, 1.5, (10, 128))
    geo_info = []
    for i in range(10):
        for j in range(128):
            geo_info.append({
                "nx": 300, "ny": 200, "dx": 2e-6, "dy": 2e-6,
                "r_in": (30, 100), "r_out": (270, 100)
            })

# Define the nonlinear material model for CIFAR-10
def infer_photonic_output_cifar10(x_input):
    """Simulate inference for a 128-feature input sample on 10-output photonic network."""
    M, N = patterns.shape[:2]  # M=10 outputs, N=128 inputs
    outputs = np.zeros(M)      # 10 outputs
    I_in = np.array(x_input)

    for i in range(M):  # outputs (10 classes)
        for j in range(N):  # inputs (128 features)
            P = patterns[i, j]
            geo_dict = geo_info[i * N + j]

            # Reconstruct geometry
            class Geo: pass
            geo = Geo()
            geo.dx, geo.dy = geo_dict["dx"], geo_dict["dy"]
            geo.nx, geo.ny = geo_dict["nx"], geo_dict["ny"]
            geo.r_in = tuple(geo_dict["r_in"])
            geo.r_out = tuple(geo_dict["r_out"])

            # Propagate intensity for this input–output link
            I_single = np.linspace(0, I_in[j], 20)
            O_single = propagate_through_pumped_material(
                I_single, P, geo, geo.r_in, geo.r_out,
                dz_steps=400, alpha_lin=200.0, g0=500.0, k_nl=2000.0, Isat=1e-3
            )
            outputs[i] += O_single[-1]  # accumulate at output i

    # Normalize total optical power (like softmax)
    if outputs.sum() > 0:
        outputs /= outputs.sum()
    return outputs

def normalize_for_optical(x_input):
    # Convert normalized features → [0, 1] range
    x_min, x_max = x_input.min(), x_input.max()
    if x_max > x_min:
        x_scaled = (x_input - x_min) / (x_max - x_min)
    else:
        x_scaled = np.zeros_like(x_input)
    return x_scaled

# Load CIFAR-10 test sample
print("\nTesting with CIFAR-10 image...")
transform_test = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),
                         std=(0.2470, 0.2435, 0.2616)),
])

testset = torchvision.datasets.CIFAR10(root="./data", train=False, download=True, transform=transform_test)
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Get a test image
test_img, test_label = testset[0]
x_test_flat = test_img.numpy().flatten()

# Load PCA transformer
try:
    with open("./pca_transformer_cifar10.pkl", "rb") as f:
        pca = pickle.load(f)
    x_test_reduced = pca.transform(x_test_flat.reshape(1, -1))[0]
    print(f"Image reduced from {len(x_test_flat)} to {len(x_test_reduced)} features")
except FileNotFoundError:
    print("PCA transformer not found, using subset of features")
    x_test_reduced = x_test_flat[:128]

# Normalize for optical processing
x_new_scaled = normalize_for_optical(x_test_reduced)
result = infer_photonic_output_cifar10(x_new_scaled)
predicted_class = np.argmax(result)

print(f"\nTrue label: {classes[test_label]}")
print(f"Predicted output intensities: {result}")
print(f"Predicted class: {classes[predicted_class]}")
